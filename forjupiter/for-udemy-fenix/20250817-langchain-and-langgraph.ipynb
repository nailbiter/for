{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f6f399-8c3b-4af3-ae8c-a1ac0a62a7df",
   "metadata": {},
   "source": [
    "* https://docs.google.com/document/d/1b7DlLtvrVxihcO65dsBaIjUU-a6aLjdQfNHSOM2PhUM/edit?tab=t.0#heading=h.v0phdvfalpr2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc866dac-b1b0-4ce4-9990-5dea8256244e",
   "metadata": {},
   "source": [
    "## setup and tryout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a239417-e284-42ed-92dc-ba8ead8b34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7f99fa0-3230-4882-8265-952753150d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# from openai import OpenAI\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96269410-51db-42e0-82ee-dd0dc0833e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Developing with LangChain effectively requires understanding its core components and applying best practices for efficiency, maintainability, and responsible AI usage. Here's a breakdown of key areas and recommended practices:\n",
      "\n",
      "**1. Understanding LangChain Components & Architecture:**\n",
      "\n",
      "*   **LLMs (Large Language Models):**  Familiarize yourself with different LLMs (OpenAI, Cohere, Hugging Face models, etc.) and their strengths and weaknesses. Choose the right model for your task (e.g., GPT-3.5 for cost-effectiveness, GPT-4 for advanced reasoning).\n",
      "*   **Prompts & Prompt Templates:**  Master prompt engineering. Understand how to craft effective prompts that guide the LLM's behavior. Use prompt templates for reusability and parameterization.\n",
      "*   **Chains:**  Learn how to chain LLMs and other components together. Chains enable complex workflows, from simple summarization to sophisticated question-answering systems.\n",
      "*   **Indexes:**  Utilize indexes (e.g., document loaders, retrievers, vectorstores) to efficiently manage and search through large datasets.  Understand the trade-offs of different indexing techniques.\n",
      "*   **Agents:**  Explore agents, which use LLMs to decide which actions to take (e.g., calling APIs, searching the web).  Understand their capabilities and limitations.\n",
      "*   **Memory:**  Implement memory mechanisms to maintain context across interactions.  Choose the appropriate memory type (e.g., conversation buffer, summary memory) for your application.\n",
      "*   **Callbacks:**  Use callbacks to monitor and debug your LangChain applications. They provide insights into the inner workings of chains, agents, and LLMs.\n",
      "*   **Document Loaders & Splitters:**  Learn how to load different document types and split them into manageable chunks for processing.\n",
      "*   **Vectorstores:** Understand how to store and query embeddings generated from your documents. Choose the appropriate vectorstore (e.g., ChromaDB, FAISS, Pinecone) based on your needs.\n",
      "\n",
      "**2. Prompt Engineering Best Practices:**\n",
      "\n",
      "*   **Clarity & Specificity:**  Be clear and specific in your instructions. Avoid ambiguity.\n",
      "*   **Role-Playing:**  Assign roles to the LLM to influence its behavior (e.g., \"You are a helpful assistant...\" or \"You are a legal expert...\").\n",
      "*   **Examples (Few-Shot Learning):**  Provide examples of input-output pairs to guide the LLM's response. This is especially useful when dealing with specific formats or tasks.\n",
      "*   **Step-by-Step Instructions:** Break down complex tasks into smaller, manageable steps.\n",
      "*   **Constraints & Formatting:**  Set constraints on the output (e.g., \"Summarize in 3 sentences,\" \"Return the answer in JSON format\").  Specify desired output formats.\n",
      "*   **Iterative Refinement:**  Prompt engineering is often an iterative process. Experiment with different prompts and refine them based on the LLM's responses.\n",
      "*   **Test Prompts Regularly:**  Use a set of test cases to evaluate your prompts and ensure consistency.\n",
      "\n",
      "**3. Chain & Agent Design Best Practices:**\n",
      "\n",
      "*   **Modularity:**  Design chains and agents with modularity in mind. Break down complex tasks into smaller, reusable components.\n",
      "*   **Error Handling:**  Implement robust error handling to gracefully handle unexpected situations (e.g., API failures, invalid inputs).\n",
      "*   **Input Validation:**  Validate user inputs to prevent issues and ensure data integrity.\n",
      "*   **Contextualization:**  Provide sufficient context to LLMs and agents to improve their accuracy and relevance.\n",
      "*   **Agent Selection:**  Carefully choose the right agent type for your task. Consider the agent's reasoning capabilities, tools, and limitations.\n",
      "*   **Tool Selection (Agents):**  Select and configure tools carefully for agents.  Ensure the tools are relevant and reliable.  Consider the potential for misuse and security implications.\n",
      "*   **Chain of Thought (CoT):**  Encourage the LLM to explain its reasoning process (e.g., \"Let's think step by step...\"). This can improve accuracy and transparency.\n",
      "\n",
      "**4. Indexing & Retrieval Best Practices:**\n",
      "\n",
      "*   **Chunking Strategy:** Choose an appropriate chunking strategy based on the document type and the desired retrieval granularity.  Consider semantic meaning when chunking.\n",
      "*   **Embedding Models:** Select an embedding model that is suitable for your data and the task (e.g., OpenAI's embeddings, Sentence Transformers).\n",
      "*   **Vectorstore Selection:** Choose a vectorstore that meets your scalability, performance, and cost requirements.\n",
      "*   **Metadata:**  Add relevant metadata to your documents to enable filtering and more precise retrieval.\n",
      "*   **Hybrid Search:**  Consider using a hybrid search approach that combines keyword search with semantic search for improved accuracy.\n",
      "*   **Query Optimization:**  Optimize your queries to the vectorstore to retrieve the most relevant results.\n",
      "*   **Evaluation:** Evaluate the performance of your retrieval system using metrics like precision, recall, and F1-score.\n",
      "\n",
      "**5. Memory Management Best Practices:**\n",
      "\n",
      "*   **Choose the Right Memory Type:**  Select the memory type that aligns with your application's requirements.  Consider the context window limits of your LLM.\n",
      "*   **Context Window Awareness:**  Be mindful of the LLM's context window size.  Summarize or truncate the conversation history if needed.\n",
      "*   **Memory Overflows:** Implement mechanisms to prevent memory overflows.\n",
      "*   **Serialization & Persistence:**  Consider serializing and persisting memory to disk or a database for long-running applications.\n",
      "\n",
      "**6. Code Quality & Maintainability:**\n",
      "\n",
      "*   **Use a Version Control System (Git):**  Track your code changes and collaborate effectively.\n",
      "*   **Write Clear & Concise Code:**  Follow coding style guidelines and use meaningful variable names.\n",
      "*   **Document Your Code:**  Add comments to explain the purpose of your code and the logic behind it.\n",
      "*   **Write Unit Tests:**  Create unit tests to verify the correctness of your functions and components.\n",
      "*   **Use a Linter & Formatter:**  Use a linter (e.g., `flake8`, `pylint`) and a formatter (e.g., `black`, `autopep8`) to maintain consistent code style.\n",
      "*   **Modularize Your Code:** Break down your code into reusable functions and classes.\n",
      "*   **Refactor Regularly:**  Refactor your code to improve its readability, maintainability, and performance.\n",
      "*   **Follow SOLID principles:** Apply object-oriented design principles for well-structured code.\n",
      "\n",
      "**7. Responsible AI Practices:**\n",
      "\n",
      "*   **Bias Detection & Mitigation:**  Be aware of potential biases in LLMs and your data.  Implement strategies to mitigate bias (e.g., data augmentation, prompt engineering).\n",
      "*   **Transparency & Explainability:**  Strive for transparency in your LLM-based systems.  Provide explanations for the LLM's decisions.\n",
      "*   **Human Oversight:**  Implement human oversight where appropriate, especially in high-stakes applications.\n",
      "*   **Data Privacy & Security:**  Protect user data and comply with privacy regulations.  Implement security measures to prevent unauthorized access.\n",
      "*   **Avoid Hallucinations:**  Be aware of the risk of LLMs generating false or misleading information (hallucinations).  Implement techniques to reduce hallucinations (e.g., grounding in reliable sources, confidence scores).\n",
      "*   **Content Moderation:**  Implement content moderation mechanisms to prevent the generation of harmful or offensive content.\n",
      "*   **Consider the Impact:**  Think about the potential societal impact of your application and address any ethical concerns.\n",
      "*   **Documentation:** Document your system's capabilities, limitations, and intended use cases.\n",
      "\n",
      "**8. Debugging & Monitoring:**\n",
      "\n",
      "*   **Use Callbacks:**  Leverage LangChain's callback system to monitor the execution of chains and agents.\n",
      "*   **Logging:**  Implement comprehensive logging to track events, errors, and performance metrics.\n",
      "*   **Error Reporting:**  Implement error reporting mechanisms to capture and analyze errors.\n",
      "*   **Performance Monitoring:**  Monitor the performance of your LLM-based applications (e.g., latency, throughput, cost).\n",
      "*   **Experimentation:**  Experiment with different configurations and evaluate their impact on performance and accuracy.\n",
      "\n",
      "**9. Deployment & Scaling:**\n",
      "\n",
      "*   **Infrastructure:** Choose the appropriate infrastructure for deploying your application (e.g., cloud platforms, containerization).\n",
      "*   **Scalability:** Design your application to scale to handle increasing workloads.  Consider techniques like load balancing and caching.\n",
      "*   **Cost Optimization:**  Optimize your application for cost-effectiveness.  Monitor your usage of LLMs and other resources.\n",
      "*   **API Management:**  Use an API gateway to manage access to your application and provide security.\n",
      "*   **CI/CD:**  Implement continuous integration and continuous deployment (CI/CD) to automate the deployment process.\n",
      "\n",
      "**10. Staying Up-to-Date:**\n",
      "\n",
      "*   **Follow LangChain Updates:**  Keep up-to-date with the latest LangChain releases, features, and bug fixes.\n",
      "*   **Read Documentation:**  Consult the official LangChain documentation regularly.\n",
      "*   **Explore Examples & Tutorials:**  Learn from LangChain's examples and tutorials.\n",
      "*   **Join the Community:**  Participate in the LangChain community (e.g., forums, Discord) to learn from others and share your experiences.\n",
      "*   **Experiment and Learn:**  Continually experiment with new techniques and technologies to improve your skills.\n",
      "\n",
      "By following these best practices, you can develop robust, maintainable, and responsible LangChain applications that effectively leverage the power of LLMs. Remember that the field of LLMs is rapidly evolving, so continuous learning and adaptation are crucial.\n",
      "CPU times: user 28.8 ms, sys: 17.9 ms, total: 46.7 ms\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Make sure to set your GOOGLE_API_KEY environment variable\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-lite\")\n",
    "\n",
    "response = llm.invoke(\"What are the best practices for developing with LangChain?\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a078a1-9f34-4f21-a57b-3435bd23bf9f",
   "metadata": {},
   "source": [
    "original:\n",
    "\n",
    "```python\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "# chat = ChatOpenAI(openai_api_key=\"...\")\n",
    "# If you have an envionrment variable set for OPENAI_API_KEY, you can just do:\n",
    "chat = ChatOpenAI()\n",
    "chat.invoke(\"Hello, how are you?\") \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "654b4fcb-f826-4012-96b9-a35fa19c5c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am doing well, thank you for asking! As a large language model, I don't experience emotions like humans do, but I am functioning properly and ready to assist you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Make sure to set your GOOGLE_API_KEY environment variable.\n",
    "# You can get one from Google AI Studio: https://aistudio.google.com/app/apikey\n",
    "\n",
    "# Initialize the Gemini chat model\n",
    "# You can also specify other models like \"gemini-1.5-pro\"\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-lite\")\n",
    "# Invoke the model with a prompt\n",
    "response = chat.invoke(\"Hello, how are you?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0333dc9-a2a4-4b45-9bf1-02348ff467b3",
   "metadata": {},
   "source": [
    "## 85 Chat Models -- Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95c4b12e-cda6-4142-ac41-f61911adfd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The capital of France is **Paris**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "response = chat.invoke(\"What is the capital of France?\")\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abb264da-cacc-4fa9-87c0-b7a305281b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_feedback': {'block_reason': 0, 'safety_ratings': []},\n",
       " 'finish_reason': 'STOP',\n",
       " 'model_name': 'gemini-2.0-flash-lite',\n",
       " 'safety_ratings': []}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0f7d4-5d29-45c2-bcd3-385cfcfccc53",
   "metadata": {},
   "source": [
    "original:\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "result = chat.invoke(messages)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5784b22-dce4-4992-9562-cd3af0fa1f0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some company name ideas for a colorful sock company, categorized for different vibes:\n",
      "\n",
      "**Playful & Fun:**\n",
      "\n",
      "*   Socktastic!\n",
      "*   Sole Mates\n",
      "*   Rainbow Threads\n",
      "*   Happy Feet Socks\n",
      "*   The Sock Drawer\n",
      "*   Crazy Socks Co.\n",
      "*   Pattern Party\n",
      "*   Sockalicious\n",
      "*   Toe-riffic Socks\n",
      "*   Wacky Walkers\n",
      "\n",
      "**Stylish & Modern:**\n",
      "\n",
      "*   Chromatic Soles\n",
      "*   Colorwave Socks\n",
      "*   Vivid Threads\n",
      "*   The Bold Sock\n",
      "*   Strata Socks\n",
      "*   Lumina Socks\n",
      "*   Artsy Soles\n",
      "*   Palette Socks\n",
      "*   Sock Theory\n",
      "*   The Colour Collective\n",
      "\n",
      "**Classic & Trustworthy:**\n",
      "\n",
      "*   The Sock Mill\n",
      "*   Comfy Colors\n",
      "*   Heritage Hosiery\n",
      "*   The Fine Sock Company\n",
      "*   Everyday Socks\n",
      "*   The Socksmith\n",
      "*   Classic Threads\n",
      "*   True Colors Socks\n",
      "*   Footprints of Style\n",
      "*   Sock & Sole\n",
      "\n",
      "**Unique & Creative:**\n",
      "\n",
      "*   Chromatic Creatures (if socks have unique patterns)\n",
      "*   The Sock Alchemist\n",
      "*   Foot Canvas\n",
      "*   Sole Symphony\n",
      "*   The Sock Parade\n",
      "*   Thread & Tone\n",
      "*   The Curious Sock\n",
      "*   Pattern Play\n",
      "*   Socktopia\n",
      "*   Kicks & Colors\n",
      "\n",
      "**Tips for Choosing a Name:**\n",
      "\n",
      "*   **Target Audience:** Who are you selling to? (Kids, adults, specific interests?)\n",
      "*   **Brand Personality:** What feeling do you want to evoke? (Fun, sophisticated, eco-friendly?)\n",
      "*   **Memorability:** Is it easy to remember and pronounce?\n",
      "*   **Availability:** Check if the name and domain name are available.\n",
      "*   **Relevance:** Does it relate to socks and the colorful aspect?\n",
      "*   **Short and Sweet:** Shorter names are often easier to remember.\n",
      "\n",
      "Consider what makes your socks unique (patterns, materials, target audience) and let that inspire your final choice! Good luck!\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Ensure your GOOGLE_API_KEY environment variable is set\n",
    "# 1. Initialize the Gemini chat model\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-lite\")\n",
    "\n",
    "# 2. Define the message(s) for the model\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "# 3. Invoke the model with the messages\n",
    "result = chat.invoke(messages)\n",
    "\n",
    "# 4. Print the AI's response content\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-for-genai",
   "language": "python",
   "name": "conda-for-genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
