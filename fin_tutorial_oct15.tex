\documentclass[8pt]{article} % use larger type; default would be 10pt

\usepackage{graphicx}
\usepackage{float}
\usepackage{subfig}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{cancel}
\usepackage{ulem}

\usepackage{mystyle}
\newcommand{\myfrac}[2]{^{#1}/_{#2}}

\title{Math 1540\\University Mathematics for Financial Studies\\2013-14 Term 1\\Suggested problems for tutorial on\\October 15, 2013}
\date{}
\begin{document}
\maketitle
In this tutorial we will practice in computing the inverse of a matrix via the explicit formulas provided by the adjoint matrix concept, as well as solving systems of linear
equations, again using the explicit formulas given by the Cramer Rule. For simplicity, we shall restrict ourselves to the matrices of size $3\times3$.

\section{Inverse Matrix via the Adjoint Matrix (theory)}
Essentially, the process is done in a four steps, as outlined below
\[A=\begin{pmatrix}a_{11}&a_{12}&\hdots&a_{1n}\\a_{21}&a_{22}&\hdots&a_{2n}\\\vdots&\vdots&\ddots&\vdots\\a_{n1}&a_{n2}&\hdots&a_{nn}\end{pmatrix}
	\xrightarrow{\text{cofactor matrix}}
	\begin{pmatrix}\det M_{11}&\det M_{12}&\hdots&\det M_{1n}\\\det M_{21}&\det M_{22}&
		\hdots&\det M_{2n}\\\vdots&\vdots&\ddots&\vdots\\\det M_{n1}&\det M_{n2}&\hdots&\det M_{nn}\end{pmatrix}\]
	\[\xrightarrow{\text{change signs in chessboard pattern}}
	\begin{pmatrix}+\det M_{11}&-\det M_{12}&\hdots&(-1)^{1+n}\det M_{1n}\\-\det M_{21}&+\det M_{22}&
		\hdots&(-1)^{2+n}\det M_{2n}\\\vdots&\vdots&\ddots&\vdots\\(-1)^{n+1}\det M_{n1}&(-1)^{n+2}\det M_{n2}&\hdots&+\det M_{nn}\end{pmatrix}
		\]
	\[\xrightarrow{\text{transpose}}
	\begin{pmatrix}+\det M_{11}&-\det M_{21}&\hdots&(-1)^{n+1}\det M_{n1}\\-\det M_{12}&+\det M_{22}&
		\hdots&(-1)^{n+2}\det M_{n2}\\\vdots&\vdots&\ddots&\vdots\\(-1)^{1+n}\det M_{1n}&(-1)^{2+n}\det M_{2n}&\hdots&+\det M_{nn}\end{pmatrix}
		\]
	\[\xrightarrow{\text{divide by $\det(A)$}}
	\frac{1}{\det(A)}\begin{pmatrix}+\det M_{11}&-\det M_{21}&\hdots&(-1)^{n+1}\det M_{n1}\\-\det M_{12}&+\det M_{22}&
		\hdots&(-1)^{n+2}\det M_{n2}\\\vdots&\vdots&\ddots&\vdots\\(-1)^{1+n}\det M_{1n}&(-1)^{2+n}\det M_{2n}&\hdots&+\det M_{nn}\end{pmatrix}
		=A^{-1}\]
	To summarize,
	\begin{enumerate}
		\item As you see, on a first step we replace each $a_{ij}$ with $\det M_{ij}$, where $M_{ij}$ denotes the matrix that is obtained
			from $A$ by cutting \textit{$i$-th row and $j$-th column}. So, for example for 
			\[A=\begin{pmatrix}1&2&3\\4&5&6\\7&8&9\end{pmatrix}\] we have 
				\[M_{23}=\begin{pmatrix}1&2&\cancel{3}\\
					\cancel{4}&\cancel{5}&\cancel{6}\\
					7&8&\cancel{9}\end{pmatrix}=
					\begin{pmatrix}1&2\\7&8\end{pmatrix}\]
		\item Next, we change the signs in a chessboard pattern, so for example
			\[A=\begin{pmatrix}1&2&3\\4&5&6\\7&8&9\end{pmatrix}\] becomes
			\[A=\begin{pmatrix}+1&-2&+3\\-4&+5&-6\\+7&-8&+9\end{pmatrix}\]
		\item Transposition goes next
		\item And finally we divide by $\det A$.
	\end{enumerate}
Before proceeding to the examples, let us make one remark.\\
\textbf{Remark. } The algorithm above should \textit{never} be used for computing inverse in real life. It is \textit{extremely} slow when
compared to the row reduction method (i.e. write augmented matrix $(A\mid I)$ and bring it to reduced row echelon form to get $(I\mid A^{-1})$).
It is rather a nice theoretical tool which allows one to prove some statements and is almost useful for practical people.
\section{Inverse Matrix via the Adjoint Matrix (examples)}
To illustrate the discussion above, let us work through the two examples
\begin{myeg}
\[A=\left(\begin{array}{rrr}
1&2&3\\
0&4&5\\
1&0&6\\
\end{array}\right)
	\xrightarrow{\text{cofactor matrix}}\left(\begin{array}{rrr}
24&-5&-4\\
12&3&-2\\
-2&5&4\\
\end{array}\right)
		\]
	\[\xrightarrow{\text{change signs in chessboard pattern}}
\left(\begin{array}{rrr}24&5&-4\\
-12&3&2\\
-2&-5&4\\
\end{array}\right)
		\]
	\[\xrightarrow{\text{transpose}}
\left(\begin{array}{rrr}
24&-12&-2\\
5&3&-5\\
-4&2&4\\
\end{array}\right)
		\]
		\[\xrightarrow{\text{divide by $\det(A)$}}\frac{1}{22}
\left(\begin{array}{rrr}
24&-12&-2\\
5&3&-5\\
-4&2&4\\
\end{array}\right)
		=A^{-1}\]
\textbf{Remark. } Note, that for matrices of high dimension (e.g. with {more }than 2 rows) the computation of the determinant via recursive
formula $\sum_{i=1}^n (-1)^{1+i}a_{1i}\det(M_{1i})$ becomes \textit{extremely inefficient and slow
} when compared to computation via the row reduction. Hence, recursive expansion
\textit{should be avoided} when matrix has more than 2 rows in favor of row reduction
. As an illustration, let us compute $\det(A)$ via the row reduction
\[
\det(A)=
\left|\begin{array}{rrr}
1&2&3\\
0&4&5\\
1&0&6\\
\end{array}\right|=
\left|\begin{array}{rrr}
1&2&3\\
0&4&5\\
0&-2&3\\
\end{array}\right|=
\left|\begin{array}{rrr}
1&2&3\\
0&4&5\\
0&0&\myfrac{11}{2}\\
\end{array}\right|=1\cdot4\cdot\frac{11}{2}=22
\]
\end{myeg}
\begin{myeg}
\[A=
\left(\begin{array}{rrr}
1&2&3\\
0&1&4\\
5&6&0\\
\end{array}\right)
	\xrightarrow{\text{cofactor matrix}}
\left(\begin{array}{rrr}
-24&-20&-5\\
-18&-15&-4\\
5&4&1\\
\end{array}\right)
		\]
	\[\xrightarrow{\text{change signs in chessboard pattern}}
\left(\begin{array}{rrr}
-24&20&-5\\
18&-15&4\\
5&-4&1\\
\end{array}\right)
		\]
	\[\xrightarrow{\text{transpose}}
\left(\begin{array}{rrr}
-24&18&5\\
20&-15&-4\\
-5&4&1\\
\end{array}\right)
		\]
		\[\xrightarrow{\text{divide by $\det(A)$}}\frac{1}{1}
\left(\begin{array}{rrr}
-24&18&5\\
20&-15&-4\\
-5&4&1\\
\end{array}\right)
		=A^{-1}\]
\end{myeg}
\section{Cramer's Rule (theory)}
Recall, that similarly to how the concept of adjoint matrix gives us an explicit formula to compute the inverse of a matrix, Cramer's Rule gives
us an explicit formulas to compute the solution of linear systems. Before, we shall proceed, let us make one remark, similar in spirit to those
we've made for determinant and adjoint matrix above.\\
\textbf{Remark. }Again, Cramer's Rule is rather a tool in theoretical construction, not a feasible way to solve real linear systems. It is
\textit{much } slower than the usual Gaussian elimination, when implemented naively.

Given linear system \[Ax=b\]
with non-singular matrix $A$, Cramer's Rule tells us that the solution to it is given by
\[x_i=\frac{\det(A_i)}{\det(A)},\;1\leq i\leq n\]
where $A_i$ denotes matrix $A$ with $i$-th column replaced by $b$.

For example, for \[A=\begin{pmatrix}1&2&3\\4&5&6\\7&8&9\end{pmatrix},\quad b=\begin{pmatrix}10\\11\\12\end{pmatrix}\]
we have
\[A_3=
\begin{pmatrix}1&2&\cancel{3}\\4&5&{\cancel{6}}\\7&8&\cancel{9}\end{pmatrix}=
\begin{pmatrix}1&2&\uline{10}\\4&5&{\uline{11}}\\7&8&\uline{12}\end{pmatrix}\]
\section{Cramer's Rule (example)}
Let us now work through a single example. Suppose we wish to solve the system
\begin{myeg}
\[Ax=
\left(\begin{array}{rrr}
1&1&3\\
3&6&8\\
5&8&18\\
\end{array}\right)\cdot\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix}=\begin{pmatrix}1\\3\\5\end{pmatrix}\]
Now, following Cramer's Rule
\[\det(A)=
\left|\begin{array}{rrr}
	2&1&3\\2&6&8\\6&8&18
\end{array}\right|=
\left|\begin{array}{rrr}
	2&1&3\\0&5&5\\0&5&9
\end{array}\right|=
\left|\begin{array}{rrr}
	2&1&3\\0&5&5\\0&0&4
\end{array}\right|=2\cdot5\cdot4=40
\]
\[\det(A_1)=\left|\begin{array}{rrr}1&1&3\\3&6&8\\5&8&18\\
\end{array}\right|=
\left|\begin{array}{rrr}1&1&3\\0&3&-1\\0&3&3\\\end{array}\right|=\left|\begin{array}{rrr}1&1&3\\0&3&-1\\0&0&4\\\end{array}\right|=1\cdot3\cdot4=12
	\implies\;x_1=\frac{\det(A_1)}{\det(A)}=\frac{12}{40}=\frac{3}{10}\]
\[\det(A_2)=\left|\begin{array}{rrr}2&1&3\\2&3&8\\6&5&18\\
\end{array}\right|=
\left|\begin{array}{rrr}
	2&1&3\\0&2&5\\0&2&9\\
\end{array}\right|=
\left|\begin{array}{rrr}
	2&1&3\\0&2&5\\0&0&4\\
\end{array}\right|=2\cdot2\cdot4=16
	\implies\;x_2=\frac{\det(A_2)}{\det(A)}=\frac{16}{40}=\frac{2}{5}\]
\[\det(A_3)=
\left|\begin{array}{rrr}
2&1&1\\
2&6&3\\
6&8&5\\
\end{array}\right|=
\left|\begin{array}{rrr}
2&1&1\\
0&5&2\\
0&5&2\\
\end{array}\right|=
\left|\begin{array}{rrr}
2&1&1\\
0&5&2\\
0&0&0\\
\end{array}\right|=0
	\implies\;x_3=\frac{\det(A_3)}{\det(A)}=\frac{0}{40}=0\]
\end{myeg}
\section{Well-definedness of the determinant}
During the course, the determinant of a matrix $A$ with
entries was defined via the recursive formula $\det(A)=\sum_{i=1}^n(-1)^{1+i}a_{1i}\det(A_{1i})$,
when $A_{1i}$ denotes the matrix $A$ with first row and $i$-th column cut out. Now, it was \textit{claimed} that in fact expansion
can be done via \textit{any} row. Hence, the question naturally arises about providing a formal proof of this fact. This section
is an attempt to provide such a proof. 

The explanation is probably not very illustrative, it is meant rather for completeness sake, than for illumination. However, the basic idea
is rather simple: we proceed by math induction on the size of matrix. Then, having to show that expansion along two rows $i<j$ gives us the same
result, we first expand along the $i$-th row, and then expand each cofactor (which in turn is determinant) by $j-1$-st row (inductive assumption
tells us that cofactors, as they are smaller than the original matrix, can be expanded freely along any row) and similarly when
expansion is done along the $j$-th row, we next expand cofactors along the $i$-th row. The two "two-level" expansions are easily seen to be
identical, which ends the proof.

Let us proceed by induction on number of rows in matrix.
For $n=2$, we have an explicit formula for the determinant and it is purely mechanical to verify that expansion
along any row gives the same result. So, assume that determinant does not change when we expand along any row for all matrices of with smaller
than $n$ rows. Now,
assume we are given a matrix $A$ of size $n\times n$ and we are trying to determine whether expanding its determinant along two different
rows will give the same result. If we'll be able to show that this indeed is true, the general result will follow by mathematical induction. Let
us fix two indices $1\leq i<j\leq n$ and show that expansion along $i$ and along $j$ will give the same result.

For this, let us first fix a bit of a notation. Given $m\times n$ matrix $A$ and
$1\leq r_1<r_2<\hdots<r_s\leq m$, let us denote by $[A]^{r_1,r_2,\hdots,r_s}$
the matrix $A$ with rows $r_1, r_2,\hdots,r_s$ cut out.
Similarly, given $1\leq c_1<c_2<\hdots<c_s\leq n$
by $[A]_{c_1,c_2,\hdots,c_s}$ we shall denote the matrix $A$ with columns $c_1,c_2,\hdots,c_s$ cut out. In case we will cut both row and columns
at the same time, we shall use the notation $[A]_{c_1,c_2,\hdots,c_s}^{r_1',r_2',\hdots,r_{s'}'}$ with natural meaning. In this new notation the 
expansion of the determinant of $A$ along the $i$-th row can be written as
\[\sum_{k=1}^n(-1)^{i+k}a_{ik}\det([A]_k^i)\]
and expansion along the $j$-th row as
\[\sum_{k=1}^n(-1)^{j+k}a_{jk}\det([A]_k^j)\]
Our goal then is to show that these two quantities are the same.

Before doing so, let us examine how successive cuts interact. The formula goes as
\[\mysbra{\mysbra{A}_k}_l=\begin{cases}\mysbra{A}_{l,k},\mbox{ if }l<k\\\mysbra{A}_{k,l+1},\mbox{ if }l\geq k\end{cases}\]
	and similarly for rows. What this formula says, is nothing but the following. If we first cut column with index
	$k$, then column with index $l<k$ (here indexes are taken already in "cut" matrix!), this is the same as cut columns $l$ and $k$ from the 
	original one, i.e. column with index $l$ in the cut matrix corresponds to column with the same index in the original one. The situation is
	different, however, when $k\leq l$, as in this case column of index $l$ in cut matrix corresponds to the column of index
	$l+1$ in the original
	one (as all the columns with index bigger than $k$ have their index reduced by 1 after the cut). Similar login gives us the correspondence
	between the indexes of elements in matrix with one
	column cut out and the original one (here by $(A)_{ab}$ or $(A)_{a,b}$ we denote element of $A$ on $a$-th row and $b$-th 
	column)
	\[\mybra{\mysbra{A}_k}_{ml}=\begin{cases}
		\mybra{A}_{ml},\mbox{ if }l<k\\
		\mybra{A}_{m,l+1},\mbox{ if }l\geq k
	\end{cases}\]

Having armed ourselves with a formal notation and means of operating on it, everything becomes mechanical
\newcommand{\sgn}{\mbox{sgn}}
\begin{gather*}
	\sum_{k=1}^n(-1)^{i+k}a_{ik}\det([A]_k^i)=\mbox{ (we expand cofactors $\det([A]_k^i)$ along the $(j-1)$-st row)}\\
	=\sum_{k=1}^n(-1)^{i+k}a_{ik}\sum_{l=1}^{n-1}\mybra{[A]_k^i}_{j-1,l}(-1)^{j-1+l}\det\mybra{\mysbra{\mysbra{A}_k^i}_l^{j-1}}=\\
	=\sum_{k=1}^n(-1)^{i+k}a_{ik}\left(
		\sum_{l=1}^{k-1}a_{j,l}(-1)^{j-1+l}\det\mybra{\mysbra{A}^{i,j}_{l,k}}+
		\sum_{l=k}^{n0}a_{j,l+1}(-1)^{j-1+l}\det\mybra{\mysbra{A}^{i,j}_{k,l+1}}
	\right)=\\
	=\sum_{k=1}^n(-1)^{i+k}a_{ik}\left(
		\sum_{l=1}^{k-1}a_{j,l}(-1)^{j-1+l}\det\mybra{\mysbra{A}^{i,j}_{l,k}}+
		\sum_{l=k+1}^{n}a_{j,l}(-1)^{j+l}\det\mybra{\mysbra{A}^{i,j}_{k,l}}
	\right)=\\
	=\sum_{{\begin{subarray}{c}k,l=1\\k\neq l\end{subarray}}
	}^n(-1)^{i+k+j+l}\sgn(l-k)a_{ik}a_{jl}\det\mybra{\mysbra{A}^{i,j}_{l,k}}
\end{gather*}
The expression $\sum_{{\begin{subarray}{c}k,l=1\\k\neq l\end{subarray}}}^n$ here denotes {\it double sum}, that is sum with all possible
combinations of $1\leq k,l\leq n$, such that $k\neq l$.
And for expansion along the row $j$, we get
\begin{gather*}
	\sum_{k=1}^n(-1)^{j+k}a_{jk}\det([A]_k^j)=\mbox{ (we expand cofactors $\det([A]_k^j)$ along the $i$-th row)}\\
	=\sum_{k=1}^n(-1)^{j+k}a_{jk}\sum_{l=1}^{n-1}\mybra{[A]_k^j}_{i,l}(-1)^{i+l}\det\mybra{\mysbra{\mysbra{A}_k^j}_l^i}=\\
	=\sum_{k=1}^n(-1)^{j+k}a_{jk}\left(
		\sum_{l=1}^{k-1}a_{i,l}(-1)^{i+l}\det\mybra{\mysbra{A}^{i,j}_{l,k}}+
		\sum_{l=k}^{n-1}a_{j,l+1}(-1)^{i+l}\det\mybra{\mysbra{A}^{i,j}_{k,l+1}}
	\right)=\\
	=\sum_{k=1}^n(-1)^{j+k}a_{jk}\left(
		\sum_{l=1}^{k-1}a_{i,l}(-1)^{i+l}\det\mybra{\mysbra{A}^{i,j}_{l,k}}+
		\sum_{l=k+1}^{n}a_{j,l}(-1)^{i+l-1}\det\mybra{\mysbra{A}^{i,j}_{k,l}}
	\right)=\\
	=\sum_{{\begin{subarray}{c}\\k\neq l\end{subarray}}
		}^n(-1)^{i+k+j+l}\sgn(k-l)a_{jk}a_{il}\det\mybra{\mysbra{A}^{i,j}_{l,k}}=\mbox{ interchanging $k$ and $l$ gives}\\
	=\sum_{{\begin{subarray}{c}k,l=1\\k\neq l\end{subarray}}
	}^n(-1)^{i+k+j+l}\sgn(l-k)a_{ik}a_{jl}\det\mybra{\mysbra{A}^{i,j}_{l,k}}
\end{gather*}
Two expansions yield the same expression, thus finishing the proof. $\myqed$
\end{document}
